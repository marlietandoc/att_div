---
title: 'Dividing attention hurts learning in adults but not children'
author: "Marlie Tandoc"
date: "11/26/2022"
output: html_document
---

```{r setup, include=FALSE,warning=FALSE}
options(rlib_downstream_check = FALSE)
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)

library(rmarkdown) #rmarkdown
library(plyr) #tidyverse
library(dplyr)#tidyverse
library(tidyr)#tidyverse
library(ggplot2) #plotting
library(ggpubr) #plotting
library(gridExtra) #plotting
require(lme4) #for mixed models
library(lmerTest) #computes p-values for mixed models
library(emmeans) #computes estimated marginal means for mixed models
library(ggsignif) #for plotting significance stars
library(ggeffects) #for plotting model estimates
library(ggbeeswarm) #For plotting distributions
library(sjPlot) #For model tables

```

## Data cleaning and restructuring
Applies exlusion criteria reported in the manuscript
```{r data_prep}

#Define and set home project directory 
home_dir <- "~/Documents/GitHub/lantern_code_sample"
setwd(home_dir)

#### READ IN ALL DATA ####

#Read in E1 data 
setwd("e1")  #Read in Lantern 1 data (with nback)
prime_files <- list.files(recursive=TRUE, pattern = "*prime") #Creates list of all prime files
prime_data <-do.call(rbind.fill,lapply(prime_files,read.csv)) #Makes big dataframe of all prime data

nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
nback_data <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big dataframe of all nback data

#Read in E2 data
setwd(paste(home_dir,"e2", sep = '/'))
nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
nback_data_e2 <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big data_e2frame of all nback data_e2

#Reset home directory and read in extra data from E2 (concatenated priming data)
setwd(home_dir) 
prime_data_e2 <- read.csv('e2_priming_data_concat.csv') #Priming data (all in one file for this experiment)

#### APPLY DATA EXCLUSION AND CLEANING ####

#E1 exclusions: These are participants whose ID was flagged in the log by research assistants as not fitting inclusion criteria (cognitive disabilities, etc.)

nback_data <- filter(nback_data, participant != 'A077')
prime_data <- filter(prime_data, participant != 'A077' )

#E2 exclusion list
exclude_from_log <- c(1002,1018,1030,1031,1070,2033,2021)
exclude_because_quit_early <- c(1011) #This participant was flagged for quitting early, so exclude
exclude_extra_participant <- c(1074)
exclude <- c(exclude_from_log,exclude_because_quit_early, exclude_extra_participant) #Master exclusion list

prime_data_e2 <- filter(prime_data_e2, !(participant %in% exclude))
nback_data_e2 <- filter(nback_data_e2, !(participant %in% exclude))

#Due to naming errors during collection, some participants have duplicate IDs
# To deal this, we make a unique ID for by attaching age to their participant ID
prime_data_e2 <- mutate(prime_data_e2, participant_str = paste(participant,age))
prime_data_e2$participant <- prime_data_e2$participant_str
nback_data_e2 <- mutate(nback_data_e2, participant_str = paste(participant,age))
nback_data_e2$participant <- nback_data_e2$participant_str

#Select only relevant variables
nback_data <- select(nback_data,participant,n_back_type,block_number,age,expected_response,user_correct, user_response,reaction_time,prime_image_id,lure) %>% mutate(experiment = 'Experiment 1')

prime_data <- select(prime_data, age, appeared_in_n_back_task, difficulty, response_correct, reaction_time, participant, condition, position,image_name) %>% mutate(experiment = 'Experiment 1')

nback_data_e2 <- select(nback_data_e2,participant,n_back_type,block_number,age,expected_response,user_correct, user_response,reaction_time,prime_image_id) %>% mutate(experiment = 'Experiment 2')
prime_data_e2 <- select(prime_data_e2, age, appeared_in_n_back_task, difficulty, response_correct, reaction_time, participant, condition, position,image_name) %>% mutate(experiment = 'Experiment 2')

#Combine prime data from E1 and E2 data together
#Note: we do not do this for nback data because the task differs across experiments
prime_data <- rbind(prime_data,prime_data_e2)

#Logs indicate participant ID 1069 was entered improperly
#Manually append C to one participant to make their ID match between nback and priming task
prime_data <- prime_data %>% mutate(participant = ifelse(participant == '1069', 'C1069', participant))

#removes empty rows from prime_data that were generated by Psychopy
prime_data <- prime_data[!is.na(prime_data$position),]

#Function that assigns each participant based on their age to an age group
#Creates two new columns:
#Age group: Child or adult
#Age new: Includes actual age for child, but age group for adult
assign_age_group <- function(data) {
  
  for (subject in 1:nrow(data)) {
    if (data$age[subject] > 12) { #If Older than 12
      data$age_group[subject] <- 'adult'
      data$age_new[subject] <- 'Adult'
    } else {
      data$age_group[subject] <- 'child'
      data$age_new[subject] <- data$age[subject]
    }
    
  }
  data
  
}

#Adds child or adult group to data
nback_data <- assign_age_group(nback_data)
prime_data <- assign_age_group(prime_data)

#Adds a new column to prime data (two_block = whether trial in prime data was in first block or second block)
for (trial in 1:nrow(prime_data)) {
  if (prime_data$position[trial] < 23) {
    prime_data$two_block[trial] <- 1
  } else {
    prime_data$two_block[trial] <- 2
  }
  
}

#Adds a new column to nback data (signal_det = signal detection theory assignment on each trial)
for (i in 1:nrow(nback_data)) {
  if(nback_data$expected_response[i] == 1) {
    if(nback_data$user_correct[i] == 1) { #If participant was correct
      nback_data$signal_det[i] <-'hit'
    } else {
      nback_data$signal_det[i] <-'miss'
    }
  } else {
    if(nback_data$user_correct[i] == 1) { #If participant was incorrect
      nback_data$signal_det[i] <-'CR' #correct rejection
    } else {
      nback_data$signal_det[i] <-'FA' #false alarm
    }
  }
}

#Experiment 1 performance-based exclusions 
e1_only_nback <- filter(nback_data, experiment == 'Experiment 1')
#Quickly summarizes n-back data to determine who to exclude
nback_quick_summary <- e1_only_nback %>% group_by(participant) %>% summarise(acc_ = length(which(user_correct == 1))/length(participant), hit_key = sum(user_response), acc_targets = length(which(user_correct == 1 & expected_response == 1))/length(which(expected_response == 1)), mean_nback = mean(n_back_type), age = age[1])

#Exclude participants 65% or lower on n-back overall and who dont hit key (0 or 1 times) 
exclusion_nback <- nback_quick_summary$participant[which(nback_quick_summary$acc_ < 0.65 | nback_quick_summary$hit_key < 2 | nback_quick_summary$hit_key > 30)] 

# filters out the participants from both dataframes who score lower than 65% on n-back
nback_data <- filter(nback_data, !(participant %in% exclusion_nback))
prime_data <- filter(prime_data, !(participant %in% exclusion_nback))

#report number of incorrect trials per age group
incorr_trials_count <- prime_data %>% 
  group_by(age_group,experiment) %>% 
  summarise(incorr_count = length(participant[which(response_correct == 0)]))

#Create new column (diff_1_rt) that has reaction time for only level 1 difficulty
prime_data['diff_1_rt'] <- 999#Mark with 999 to allow for filtering later without NAs
for (i in 1:nrow(prime_data)) {
  if (prime_data$difficulty[i] == 1) {
    prime_data$diff_1_rt[i] <- prime_data$reaction_time[i]
    
  }
}

#Number of trials that were too fast
too_fast_trials_count <- prime_data %>% group_by(age_group,experiment) %>% 
  summarise(count = length(participant[which(diff_1_rt < 0.3)]))


#Exclude prime data trials faster than 300ms (0.3s) 
prime_data<- filter(prime_data, diff_1_rt > 0.3 )

#New dataframe of correct trials only. From this point on we only use this dataframe for analysis (as per pre-registration)
correct_prime_trials = filter(prime_data, response_correct == 1)

#### CREATE SUMMARIZED DATAFRAMES ####

# Quick function that rounds decimal points for plotting
scaleFUN <- function(x) sprintf("%.1f", x)

#PRIMING PERFORMANCE FOR EACH PARTICIPANT
prime_sum_participant = correct_prime_trials %>% 
  group_by(participant,experiment) %>% 
  summarise(mean_old = mean(difficulty[which(appeared_in_n_back_task == 1)]), #Average level for old images
            mean_new = mean(difficulty[which(appeared_in_n_back_task == 0)]), #Average level for new images
            age = age[1],
            age_group = age_group[1],
            age_new = age_new[1]) %>% 
  mutate(primability_score = #Primability score 
           mean_new - mean_old) 

#PRIMING PERFORMANCE FOR EACH PARTICIPANT IN EACH BLOCK
prime_sum_participant_block = correct_prime_trials %>% 
  group_by(participant, two_block,experiment) %>% 
  summarise(mean_old = mean(difficulty[which(appeared_in_n_back_task == 1)]), #Average level for old images
            mean_new = mean(difficulty[which(appeared_in_n_back_task == 0)]), #Average level for new images
            age = age[1],
            age_group = age_group[1],
            age_new = age_new[1]) %>%
  mutate(primability_score = mean_new - mean_old) #Priambility wscore


#NBACK PERFORMANCE (EXPERIMENT 1)
nback_summary <- filter(nback_data, experiment == 'Experiment 1') %>% 
  group_by(participant,age_group) %>%
  summarise(mean_nback_level = mean(n_back_type),
            nback_acc = length(which(user_correct == 1))/92,
            hit_rate = (length(which(signal_det =='hit'))+0.5)/(length(which(expected_response == 1))+(1)),
            FA_rate = (length(which(signal_det =='FA'))+0.5)/(length(which(expected_response == 0))+(1)),
            hit_key = sum(user_response),
            nback_level_1 = n_back_type[which(block_number == 0)][1],
            nback_level_2 = n_back_type[which(block_number == 1)][1],
            nback_level_3 = n_back_type[which(block_number == 2)][2],
            nback_level_4 = n_back_type[which(block_number == 3)][3],
            total_trials = length(participant)) %>%
  mutate(nback_dprime = qnorm(hit_rate)-qnorm(FA_rate))


#### ADDITIONAL PLOTTING PREPARATION ####

#Convenient dataframes separated by experiment for plotting
plot_e1 <- filter(prime_sum_participant, experiment == 'Experiment 1')
plot_e2<- filter(prime_sum_participant, experiment == 'Experiment 2')

plot_e1_b <- filter(prime_sum_participant_block, experiment == 'Experiment 1')
plot_e2_b <- filter(prime_sum_participant_block, experiment == 'Experiment 2')

#Master dataframe of both nback and expdriment 1 data in same table to run correlations
master_sum <- merge(nback_summary, plot_e1, by = 'participant' )

#make ordered factors for plotting (child, adult)
correct_prime_trials$age_group <- factor(correct_prime_trials$age_group,levels=c("child","adult"))
nback_summary$age_group <- factor(nback_summary$age_group,levels=c("child","adult"))


#model prep (move down to statistics)
#centre
correct_prime_trials <- correct_prime_trials %>% mutate(pos_new = position + 1) #original trial 1 was 0, so add +1

correct_prime_trials <- mutate(correct_prime_trials,position_c = pos_new - 23, # centre position_c, 23 is now 0 (46 trials total)
                               block_c = ifelse(two_block == 1, -1, 1),
                               app_nback_c = ifelse(appeared_in_n_back_task == 1, 1,-1),
                               age_group_c = ifelse(age_group == 'child',1,-1),
                               experiment_c = ifelse(experiment == 'Experiment 2',1,-1))

#restructure dataframe into long
plot_raw <- gather(prime_sum_participant, trial_type, mean_difficulty, mean_old:mean_new, factor_key=TRUE)

plot_raw$experiment <- factor(plot_raw$experiment,levels=c("Experiment 2","Experiment 1"))

plot_raw_b <- gather(prime_sum_participant_block, trial_type, mean_difficulty, mean_old:mean_new, factor_key=TRUE)



#Dataframes that have both nback and priming performance for mixed modelling
e1_only <-  filter(correct_prime_trials, experiment == 'Experiment 1')
e2_only <-  filter(correct_prime_trials, experiment == 'Experiment 2')
for (i in 1:nrow(e1_only)) {
  
  curr <- filter(master_sum, participant == correct_prime_trials$participant[i])
  e1_only$nback_mean_level[i] <- curr$mean_nback_level[1]
  e1_only$nback_dprime[i] <- curr$nback_dprime[1]
  
}

#nback acc in model (mean center)
e1_only <- e1_only %>% mutate(nback_dprime_c = scale(nback_dprime))


```

## Adults only learn better than kids when attention is undivided
Age in months kids vs adults 
N-back level
Basic learning sensitivity plot undivided vs divided
Learning by age in months

```{r visuals, echo=FALSE,fig.height=6, fig.width=5,warning=FALSE}

 #Custom color scheme
  adult_hex <- '#7973c9' 
  child_hex <- '#31b8c4'
  hex_7 <-'#73bdb2'
  hex_8 <-'#73B7BD'
  hex_9 <- '#5481a8'
  
  e1a <-ggplot(filter(plot_e1), aes(x=age_group, y=primability_score, color = age_group, fill = age_group)) +
    geom_quasirandom(aes(color = age_group),alpha = 0.4,dodge.width = 0.7,stroke = 0,size = 3,width = 0.35) +
    stat_summary(fun.y=mean,position=position_dodge(width=0.7),geom='point',size = 4) +
    stat_summary(fun.data=mean_se,  geom="errorbar",lwd=1.5, fatten=1.5,width=0.09,position=position_dodge(width=0.7)) +
    theme_classic(base_size = 20)+
    geom_hline(yintercept=0) +
    scale_fill_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_color_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_x_discrete(labels = c('Child','Adult')) +
    labs(x = 'Age Group', y = 'Learning Sensitivity', fill = 'Age Group', color = 'Age Group') +
    coord_cartesian(ylim = c(-0.8,1.4))+ scale_y_continuous(breaks= seq(-0.8,1.4,0.4),labels=scaleFUN) +
    ggtitle('Divided attention') +
    theme(legend.position ='none',plot.title = element_text(hjust = 0.5)) 

  e1a
  
  
  #AS OF DEC 01 2020 - 7 X 5.5
  e2a <-ggplot(filter(plot_e2), aes(x=age_group, y=primability_score, color = age_group, fill = age_group)) +
    geom_quasirandom(aes(color = age_group),alpha = 0.4,dodge.width = 0.7,stroke = 0,size = 3,width = 0.35) +
    stat_summary(fun.y=mean,position=position_dodge(width=0.7),geom='point',size = 4) +
    stat_summary(fun.data=mean_se,  geom="errorbar",lwd=1.5, fatten=1.5,width=0.09,position=position_dodge(width=0.7)) +
    theme_classic(base_size = 20)+
    geom_hline(yintercept=0) +
    scale_fill_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_color_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_x_discrete(labels = c('Child','Adult')) +
    labs(x = 'Age Group', y = 'Learning Sensitivity', fill = 'Age Group', color = 'Age Group') +
    coord_cartesian(ylim = c(-0.8,1.4))+ scale_y_continuous(breaks= seq(-0.8,1.4,0.4),labels=scaleFUN) +
    ggtitle('Undivided attention') +
    theme(legend.position ='none',plot.title = element_text(hjust = 0.5)) 

  e2a
  
   prime_sum_participant <- prime_sum_participant %>%
    mutate(divided = ifelse(experiment == 'Experiment 1', '1Yes','2No'))
  
  
  
```

## Dividing attention hurts learning in adults, but not kids

```{r visuals_2, echo=FALSE,fig.height=6, fig.width=5,warning=FALSE}

#Order factors  
   prime_sum_participant <- prime_sum_participant %>%
    mutate(divided = ifelse(experiment == 'Experiment 1', '1Yes','2No'))
  
  across_exp_nb <-ggplot(filter(prime_sum_participant), aes(x=divided, y=primability_score, color = age_group, fill = age_group)) +
    geom_quasirandom(aes(color = age_group),alpha = 0.4,dodge.width = 0.7,stroke = 0,size = 3,width = 0.35) +
    stat_summary(fun.y=mean,position=position_dodge(width=0.7),geom='point',size = 4.5) +
    stat_summary(fun.data=mean_se,  geom="errorbar",lwd=1.5, fatten=1.5,width=0.15,position=position_dodge(width=0.7))+
    theme_classic(base_size = 25)+
    geom_hline(yintercept=0) +
    scale_fill_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_color_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    #scale_x_discrete(labels = c('Child','Adult')) +
    labs(x = 'Divided attention', y = 'Learning Sensitivity', fill = 'Age Group', color = 'Age Group') +
    coord_cartesian(ylim = c(-0.6,1.5))+ scale_y_continuous(breaks= seq(-0.8,1.4,0.4),labels=scaleFUN) +
    ggtitle('Comparing learning across experiments') +
    theme(legend.position = 'none') +
    facet_wrap(~age_group) 
  across_exp_nb
  
  
```


#Correlation
```{r visuals_correlation, echo=FALSE,fig.height=6, fig.width=5,warning=FALSE}

#Order factors  
   prime_sum_participant <- prime_sum_participant %>%
    mutate(divided = ifelse(experiment == 'Experiment 1', '1Yes','2No'))
  
  across_exp_nb <-ggplot(filter(prime_sum_participant), aes(x=divided, y=primability_score, color = age_group, fill = age_group)) +
    geom_quasirandom(aes(color = age_group),alpha = 0.4,dodge.width = 0.7,stroke = 0,size = 3,width = 0.35) +
    stat_summary(fun.y=mean,position=position_dodge(width=0.7),geom='point',size = 4.5) +
    stat_summary(fun.data=mean_se,  geom="errorbar",lwd=1.5, fatten=1.5,width=0.15,position=position_dodge(width=0.7))+
    theme_classic(base_size = 25)+
    geom_hline(yintercept=0) +
    scale_fill_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    scale_color_manual(values=c(child_hex,adult_hex),labels = c('Child','Adult')) +
    #scale_x_discrete(labels = c('Child','Adult')) +
    labs(x = 'Divided attention', y = 'Learning Sensitivity', fill = 'Age Group', color = 'Age Group') +
    coord_cartesian(ylim = c(-0.6,1.5))+ scale_y_continuous(breaks= seq(-0.8,1.4,0.4),labels=scaleFUN) +
    ggtitle('Comparing learning across experiments') +
    theme(legend.position = 'none') +
    facet_wrap(~age_group) 
  across_exp_nb
  
  
```









```{r mixed_model_prep, echo=FALSE}

#### MODEL PREP ####
#Mean centre (_c) all vars for model so we can interpret the main effect at the average level
correct_prime_trials <- mutate(correct_prime_trials,
                               pos_new = position + 1, #Start position (trial number at 1 not 0)
                               position_c = pos_new - 23, # centre position_c, 23 is now 0 (46 trials total)
                               block_c = ifelse(two_block == 1, -1, 1),
                               app_nback_c = ifelse(appeared_in_n_back_task == 1, 1,-1),
                               age_group_c = ifelse(age_group == 'child',1,-1),
                               experiment_c = ifelse(experiment == 'Experiment 2',1,-1))

# Create convenient dataframes that have both nback and priming performance for modeling
e1_only <-  filter(correct_prime_trials, experiment == 'Experiment 1')
e2_only <-  filter(correct_prime_trials, experiment == 'Experiment 2')

for (i in 1:nrow(e1_only)) {
  curr <- filter(master_sum, participant == correct_prime_trials$participant[i])
  e1_only$nback_mean_level[i] <- curr$mean_nback_level[1]
  e1_only$nback_dprime[i] <- curr$nback_dprime[1]
}

#Mean center dprime 
e1_only <- e1_only %>% mutate(nback_dprime_c = scale(nback_dprime))


```
## Mixed effects models: Predicting identification level
Experiment 1
```{r mixed_models, echo=FALSE, warning = FALSE}

#Test model plot
m1_lm <- lmer(difficulty~ app_nback_c * age_group *two_block + nback_dprime_c + (1|participant), data=e1_only)

test <- filter(plot_raw_b, experiment == 'Experiment 1') %>%
  mutate(app_nback_c = ifelse(trial_type == 'mean_old', 1,-1))

x <- ggpredict(m1_lm, terms = c('age_group','app_nback_c', 'two_block'))

test['facet'] <- test$two_block

ggplot(x, aes(x = x, y = predicted, color = x, fill= group)) +
  geom_point(size = 4,position = position_dodge(.95)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width=0,
                lwd = 1.5,
                position = position_dodge(.95))  +
  facet_wrap(~facet) +
  geom_quasirandom(data =filter(test, experiment == 'Experiment 1'),  
                   aes(x = age_group, y = mean_difficulty, color = age_group, fill = as.factor(app_nback_c)),
                   alpha = 0.3,dodge.width = 0.95, size = 2,stroke = 0) +
  theme_classic(base_size = 30) +
  theme(legend.position = 'none') +
  scale_color_manual(values=c(child_hex,adult_hex)) +
  scale_x_discrete(labels = c('Child','Adult'))  +
  labs(x = 'Age', y = 'Estimated identification level') 

print(m1_lm)
sjPlot:: tab_model(m1_lm)


```








## Other figure visualizations chunks

```{r other_figures, echo=FALSE}



  nback_summary_by_block_lvl <- select(nback_summary,participant, age_group,nback_level_1, nback_level_2,nback_level_3,nback_level_4)
  nback_block_long_lvl <- gather(nback_summary_by_block_lvl, block, level, nback_level_1:nback_level_2:nback_level_3:nback_level_4)
  
  #rename to numbers
  for (i in 1:nrow(nback_block_long_lvl)){
    
    if (nback_block_long_lvl$block[i] == 'nback_level_1') {
      nback_block_long_lvl$block[i] <- 1
    } else if (nback_block_long_lvl$block[i] == 'nback_level_2') {
      nback_block_long_lvl$block[i] <- 2
    } else if (nback_block_long_lvl$block[i] == 'nback_level_3') {
      nback_block_long_lvl$block[i] <- 3
    } else if (nback_block_long_lvl$block[i] == 'nback_level_4') {
      nback_block_long_lvl$block[i] <- 4
    }
    
  }
  
  #normalize to proportion of subjects
  nback_count_table_each_block <-  nback_block_long_lvl %>%
    group_by(age_group, level,block) %>%
    summarise(count_shit = length(age_group)) %>%
    mutate(normalize_shit = ifelse(age_group == 'child', count_shit/53,count_shit/60))
  
  nback_count_table_each_block$age_group <- factor(nback_count_table_each_block$age_group,levels=c("child","adult"))
  
  
  #I like this graph  for supplement
  nback_mean_level_block <- ggplot(filter(nback_count_table_each_block), aes (x = as.factor(level),y= normalize_shit, fill = age_group)) +
    geom_bar(stat="identity", position=position_dodge()) + theme_classic()+
    labs(y = 'Proportion of subjects', x = "N-Back Level") + ggtitle('N-Back Level in Each Block')+
    scale_fill_manual(values=c(child_hex,adult_hex)) +
    facet_wrap(~block,nrow = 1) +
    theme_classic(base_size = 20) +
    theme(,axis.text.x=element_text(angle=45, hjust=1),legend.position = 'top') +
    scale_x_discrete(labels = c('1-back','2-back','3-back')) 
  nback_mean_level_block

```



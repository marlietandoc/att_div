normdata <- subset(normdata, normdata$trialcode=='rating')
# trying to make a correlation matrix
library(ggplot2)
ggplot(normdata, aes(values.1stitem, values.2nditem)) +
geom_raster(aes(fill = response)) +
theme_classic()
normdata$stim1 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.2nditem,
ifelse(normdata$cond=='c', normdata$values.1stitem, NA))
normdata$stim2 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.1stitem,
ifelse(normdata$cond=='c', normdata$values.2nditem, NA))
ggplot(normdata, aes(stim1, stim2)) +
geom_raster(aes(fill = response)) +
theme_classic()
View(normdata)
# get rid of unwanted objects
normdata[normdata$subject=='1']
View(normdata)
View(normdata)
View(normdata)
#Synesthesia Winter 2018 Data
colscheme2 <- c('deeppink3', 'pink')
#### Add AV Data ####
# Set Directory to where the data files are so that you can add all the files
setwd("/Volumes/Rock/p/tess_fmri/norming/conda")
# Get all the Files from that directory and make their names into a list
filenames = list.files(path = getwd())
# Call that function on all of the files in your list of file names, and turn it into one large data frame
normdata_a <- do.call("rbind", lapply(filenames, read.csv))
normdata_a$cond <- 'a'
setwd("/Volumes/Rock/p/tess_fmri/norming/condb")
filenames = list.files(path = getwd())
normdata_b <- do.call("rbind", lapply(filenames, read.csv))
normdata_b$cond <- 'b'
setwd("/Volumes/Rock/p/tess_fmri/norming/condc")
filenames = list.files(path = getwd())
normdata_c <- do.call("rbind", lapply(filenames, read.csv))
normdata_c$cond <- 'c'
setwd("/Volumes/Rock/p/tess_fmri/norming/condd")
filenames = list.files(path = getwd())
normdata_d <- do.call("rbind", lapply(filenames, read.csv))
normdata_d$cond <- 'd'
# merge all conditions
normdata <- rbind(normdata_d, normdata_b, normdata_c, normdata_a)
# get rid of attention check trials
normdata <- subset(normdata, normdata$trialcode=='rating')
# get rid of unwanted objects
normdata[normdata$subject=='1']
# trying to make a correlation matrix
library(ggplot2)
ggplot(normdata, aes(values.1stitem, values.2nditem)) +
geom_raster(aes(fill = response)) +
theme_classic()
normdata$stim1 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.2nditem,
ifelse(normdata$cond=='c', normdata$values.1stitem, NA))
normdata$stim2 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.1stitem,
ifelse(normdata$cond=='c', normdata$values.2nditem, NA))
ggplot(normdata, aes(stim1, stim2)) +
geom_raster(aes(fill = response)) +
theme_classic()
# get rid of unwanted objects
keep <- normdata[normdata$subject=='1']
View(keep)
normdata <- normdata[normdata$subject=='1']
# get rid of attention check trials
normdata <- subset(normdata, normdata$trialcode=='rating')
# get rid of unwanted objects
normdata <- normdata[normdata$subject=='1']
normdata <- normdata[normdata$subject=='1']
View(normdata)
View(normdata)
View(normdata)
View(normdata)
View(normdata)
View(normdata)
#Synesthesia Winter 2018 Data
colscheme2 <- c('deeppink3', 'pink')
#### Add AV Data ####
# Set Directory to where the data files are so that you can add all the files
setwd("/Volumes/Rock/p/tess_fmri/norming/conda")
# Get all the Files from that directory and make their names into a list
filenames = list.files(path = getwd())
# Call that function on all of the files in your list of file names, and turn it into one large data frame
normdata_a <- do.call("rbind", lapply(filenames, read.csv))
normdata_a$cond <- 'a'
setwd("/Volumes/Rock/p/tess_fmri/norming/condb")
filenames = list.files(path = getwd())
normdata_b <- do.call("rbind", lapply(filenames, read.csv))
normdata_b$cond <- 'b'
setwd("/Volumes/Rock/p/tess_fmri/norming/condc")
filenames = list.files(path = getwd())
normdata_c <- do.call("rbind", lapply(filenames, read.csv))
normdata_c$cond <- 'c'
setwd("/Volumes/Rock/p/tess_fmri/norming/condd")
filenames = list.files(path = getwd())
normdata_d <- do.call("rbind", lapply(filenames, read.csv))
normdata_d$cond <- 'd'
# merge all conditions
normdata <- rbind(normdata_d, normdata_b, normdata_c, normdata_a)
# get rid of attention check trials
normdata <- subset(normdata, normdata$trialcode=='rating')
# trying to make a correlation matrix
library(ggplot2)
ggplot(normdata, aes(values.1stitem, values.2nditem)) +
geom_raster(aes(fill = response)) +
theme_classic()
normdata$stim1 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.2nditem,
ifelse(normdata$cond=='c', normdata$values.1stitem, NA))
normdata$stim2 <- ifelse(normdata$cond=='d'|normdata$cond=='a'|normdata$cond=='b', normdata$values.1stitem,
ifelse(normdata$cond=='c', normdata$values.2nditem, NA))
ggplot(normdata, aes(stim1, stim2)) +
geom_raster(aes(fill = response)) +
theme_classic()
View(normdata_a)
View(normdata)
#Lantern - skeleton
library(plyr)
library(dplyr)
library(ggplot2)
library(jtools)
#Global drop levels of strings before reading in any data
options(stringsAsFactors = FALSE)
#Reads in data and filters trials we don't want (MIGHT NEED TO CHANGE THIS)
wd <- setwd("~/Desktop/Lantern Analysis/marlie_to_code") #sets WD
nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
prime_files <- list.files(recursive=TRUE, pattern = "*prime") #Creates list of all prime files
nback_data <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big dataframe of all nback data
install.packages("dplyr")
#Lantern - skeleton
library(plyr)
library(dplyr)
library(ggplot2)
library(jtools)
#Global drop levels of strings before reading in any data
options(stringsAsFactors = FALSE)
#Reads in data and filters trials we don't want (MIGHT NEED TO CHANGE THIS)
wd <- setwd("~/Desktop/Include Data") #sets WD
nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
prime_files <- list.files(recursive=TRUE, pattern = "*prime") #Creates list of all prime files
nback_data <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big dataframe of all nback data
prime_data <-do.call(rbind.fill,lapply(prime_files,read.csv)) #Makes big dataframe of all prime data
#filter prime data only by trials that is correct
#Make summary dataframe to be able to run stats on and graph (i.e. each row is a participant with their primability score and age)
# Compare kids + adults primability index (i.e. mean difficulty on new items - mean difficulty on old items)
#do a t.test or use lmer function
#graph this
# Compare kids + adults primability index by splitting the prime test trials into blocks (first half and second half)
# use lmer function
#graph this
View(prime_data)
View(nback_data)
View(prime_data)
View(prime_data)
dim(prime_data)
filtered_prime_data = prime_data %>% select(age, appeared_in_n_back_task, response_correct)
head(filtered_prime_data)
View(nback_data)
unique(nback_data$participant_num)
unique(nback_data$participant)
duplicate(nback_data$participant)
duplicated(nback_data$participant)
filterprime %>% filter(participant_num = 89)
x <-  filter(prime_data, participant_num = 89)
x <-  filter(prime_data, participant_num == 89)
View(x)
head(x)
mean(user_correct)
mean(nback_data$user_correct)
mean(prime_data$response_correct)
x <- filter(prime_data, age = 7, 8, 9)
x <- filter(prime_data, age == 7, 8, 9)
head(x)
View(x)
mean(x$response_correct)
y = filter(prime_data, age != 7, 8, 9)
mean(y$response_correct)
x = filter(prime_data, age == 7, 8, 9, appeared_in_n_back_task == 1)
mean(x$response_correct)
view(x)
View(x)
mean(x$response_correct)
y - filter(prime_data, age != 7, 8, 9, appeared_in_n_back_task == 1)
y = filter(prime_data, age != 7, 8, 9, appeared_in_n_back_task == 1)
View(y)
mean(y$response_correct)
notx = filter(prime_data, age == 7, 8, 9, appeared_in_n_back_task == 1)
notx = filter(prime_data, age == 7, 8, 9, appeared_in_n_back_task == 0)
noty = filter(prime_data, age != 7, 8, 9, appeared_in_n_back_task == 0)
mean(x$response_correct)
mean(notx$response_correct)
xpercentage = mean(x$response_correct)
notxpercentage = mean(notx$response_correct)
differencex = xpercentage - notxpercentage
differencex
ypercentage = mean(y$response_correct)
notypercentage = mean(noty$response_correct)
differencey = ypercentage - notypercentage
differencey
# write primability function still....
#All Data = only data from 2019..
#old_adult_data = also data from 2018... starting from A020+
#lower level = faster, higher level = slow
#meeting questions
#raw reaction time?
library(plyr)
library(dplyr)
library(ggplot2)
library(jtools)
#Global drop levels of strings before reading in any data
options(stringsAsFactors = FALSE)
#Reads in data and filters trials we don't want (MIGHT NEED TO CHANGE THIS)
wd <- setwd("~/Desktop/Lantern Analysis/marlie_to_code") #sets WD
nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
prime_files <- list.files(recursive=TRUE, pattern = "*prime") #Creates list of all prime files
nback_data <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big dataframe of all nback data
prime_data <-do.call(rbind.fill,lapply(prime_files,read.csv)) #Makes big dataframe of all prime data
colnames(prime_data)[4] <- "old" # renames super long column name (appeared_in_n_back_task to "old)
#selects columns i only want now so  i can actually rad it
prime_data <- select(prime_data, age, old, difficulty, response_cr reaction_time, participant, condition, position)
prime_data <- na.omit(prime_data)  #removes all NA trials
# creates column for block
for (trial in 1:nrow(prime_data)) {
if (prime_data$position[trial] < 24) {
prime_data$block[trial] <- 1
} else {
prime_data$block[trial] <- 2
}
}
#prime_data<- filter(prime_data, response_correct != 0) #filters all NA responses, and no text response and ONLY COR RESP
#assigns to age bin
for (subject in 1:nrow(prime_data)) {
if (prime_data$age[subject] > 12) {
prime_data$age_group[subject] <- 'adult'
} else {
prime_data$age_group[subject] <- prime_data$age[subject]
}
}
#assigns to age group
for (subject in 1:nrow(prime_data)) {
if (prime_data$age[subject] > 12) {
prime_data$group[subject] <- 'adult'
} else {
prime_data$group[subject] <- 'kid'
}
}
#### Nback summary table ####
nback_summary <- group_by(nback_data,participant) %>%
summarize(mean_nback_level = mean(n_back_type))
# # creates column for raw reaction time on each trial CHECK HOW LONG EACH LEVLE ACTUALLY IS FIRST
#
# level_length <- 1.5 # length of each level in seconds *I DONT THINK THIS IS RIGHT?
# level_num <- 8 # number of possible levels
# for (trial in 1:nrow(prime_data)) {
#   prime_data$raw_RT[trial] = level_length*(prime_data$difficulty[trial]) + prime_data$reaction_time[trial]
#
#   }
# NOT IN PRE-REG THIS IS MY OWN DIFFICULTY INDEX
#adds reaction time onto difficulty level
# for (trial in 1:nrow(prime_data)) {
#   RT_percentage <- prime_data$reaction_time[trial]/1.5
#   prime_data$combined_score[trial] <- prime_data$difficulty[trial] + RT_percentage
# }
#
# prime_data$combined_score <- as.numeric(prime_data$combined_score) #changes combined score into integer to let us calculate things
#
#### Creates summary table for prime data #####
prime_summary <- filter(prime_data) %>%
group_by(participant, age_group, block) %>%
summarize(group = group[1],
condition = condition[1],
mean_level = mean(difficulty),
mean_old = mean(difficulty[which(old ==1)]),
mean_new = mean(difficulty[which(old ==0)]),
n_corr_trials = length(age)#,
# mean_com_old = mean(combined_score[which(old ==1)]),
#mean_com_new = mean(combined_score[which(old ==0)])
)
prime_summary <- na.omit(prime_summary)  #removes all NA participants
for (subject in 1:nrow(prime_summary)) {
prime_summary$primability_index[subject] <- (prime_summary$mean_new[subject]) - (prime_summary$mean_old[subject])
}
# for (subject in 1:nrow(prime_summary)) {
#   prime_summary$primability_index_com[subject] <- (prime_summary$mean_com_new[subject]) - (prime_summary$mean_com_old[subject])
# }
#### OTHER SUMMARY TABLES FOR GRAPHING ####
#Creates group mean tables for graphing
block_age_means <- group_by(prime_summary, age_group, block) %>% # table depicting means by block + age group
summarize(mean_primability = mean(primability_index),
sd = sd(primability_index),
thingy = (sqrt(length(primability_index)))) %>%
mutate(se = sd/thingy)
GROUPS <- group_by(prime_summary, group, block) %>% # table depicting means by block + age group
summarize(mean_primability = mean(primability_index),
sd = sd(primability_index),
thingy = (sqrt(length(primability_index)))) %>%
mutate(se = sd/thingy)
age_means <- group_by(prime_summary, age_group) %>% # table depicting means by age group
summarize(mean_primability = mean(primability_index),
sd = sd(primability_index),
thingy = (sqrt(length(primability_index)))) %>%
mutate(se = sd/thingy)
grouped_means <- group_by(prime_summary, group) %>% # table depicting means by age group
summarize(mean_primability = mean(primability_index),
sd = sd(primability_index),
thingy = (sqrt(length(primability_index)))) %>%
mutate(se = sd/thingy)
# com_means <- group_by(prime_summary, age_group, block) %>% # table depicting means by block + age group FOR COMBINED SCORE
#   summarize(mean_primability = mean(primability_index_com),
#             sd = sd(primability_index_com),
#             thingy = (sqrt(length(primability_index_com)))) %>%
#   mutate(se = sd/thingy)
#descriptive stats, quick sample size calculations
participant_desc <- group_by(prime_data, participant) %>%
summarize(age = age_group[1])
n_7 <- nrow(participant_desc[which(participant_desc$age == 7),])
n_8 <- nrow(participant_desc[which(participant_desc$age == 8),])
n_9 <- nrow(participant_desc[which(participant_desc$age == 9),])
n_adult <- nrow(participant_desc[which(participant_desc$age == 'adult'),])
n_total <- n_7 + n_8 + n_9 + n_adult
#### MASTER PARTICIPANT SUMMARY TABLE ####
#master table groups
master_summary <- merge(prime_summary, nback_summary, by = "participant") # Creates summary dataframe of prime and nback data
master_summary <- filter(master_summary, n_corr_trials > 14)  #REMOVES ALL PARTICIPANTS THAT GET LESS THAN HALF OF THE PRIME TRIALS CORRECT
#master table no groups
participant_summary <- filter(prime_data) %>%
group_by(participant) %>%
summarize(age_group = age_group[1],
group = group[1],
condition = condition[1],
mean_level = mean(difficulty),
mean_old = mean(difficulty[which(old ==1)]),
mean_new = mean(difficulty[which(old ==0)]),
n_corr_trials = length(age)#,
# mean_com_old = mean(combined_score[which(old ==1)]),
#mean_com_new = mean(combined_score[which(old ==0)])
)
for (subject in 1:nrow(participant_summary)) {
participant_summary$primability_index[subject] <- (participant_summary$mean_new[subject]) - (participant_summary$mean_old[subject])
}
participant_summary <- na.omit(participant_summary)  #removes all NA participants
participant_summary <- merge(participant_summary, nback_summary, by = "participant") # Creates summary dataframe of prime and nback data
participant_summary <- filter(participant_summary, n_corr_trials > 14)  #REMOVES ALL PARTICIPANTS THAT GET LESS THAN HALF OF THE PRIME TRIALS CORRECT
##### Statistical Tests ########################################################################################
#STILL NEED TO CHANGE T.TEST TO LM #
cor.test(participant_summary$mean_nback_level, participant_summary$primability_index)  # nback level x primability
cor.test(master_summary$mean_nback_level[which(master_summary$block == 1)], #nback level x primability for FIRST block of prime test
master_summary$primability_index[which(master_summary$block == 1)])
cor.test(master_summary$mean_nback_level[which(master_summary$block == 2)], #nback level x primability for SECOND block of prime test
master_summary$primability_index[which(master_summary$block == 2)])
# t test adults x kids on primability index
t.test(master_summary$primability_index[which(master_summary$group == 'adult')],
master_summary$primability_index[which(master_summary$group == 'kid')])
#t test only for first block
t.test(master_summary$primability_index[which(master_summary$group == 'adult' & master_summary$block == 1)],
master_summary$primability_ind[which(master_summary$group == 'kid' & master_summary$block == 1)])
#t test only for second block
t.test(master_summary$primability_index[which(master_summary$group == 'adult' & master_summary$block == 2)],
master_summary$primability_index[which(master_summary$group == 'kid' & master_summary$block == 2)])
#t test for first block only 7 year olds
t.test(master_summary$primability_index[which(master_summary$age_group == 7 & master_summary$block == 1)],
master_summary$primability_ind[which(master_summary$age_group == 'adult' & master_summary$block == 1)])
#### Graphs ################################################################################
# Main graphs
#bar graph primability index x kid/adult
ggplot(grouped_means, aes(x=group, y=mean_primability, fill = group)) +
geom_bar(stat="identity") +
ggtitle("primability x age group") +
scale_fill_manual(values=c("#932422", "#d35450")) +  labs(y = 'primability_index
(new image level - old image level') +
geom_errorbar(aes(ymin= mean_primability - se, ymax= mean_primability + se), width=.2,
position=position_dodge(.9))
#looks at early and late performance on priming test
ggplot(GROUPS, aes(fill=group, y=mean_primability, x=as.factor(block))) +
geom_bar(position="dodge", stat="identity") +
scale_fill_manual(values=c("#932422", "#d35450", "#d38381", "#394f68")) +
ggtitle("primability x block x age group") +
labs(y = 'primability_index
(new image level - old image level', x = 'block (first or second half)') +
geom_errorbar(aes(ymin= mean_primability - se, ymax= mean_primability + se), width=.2,
position=position_dodge(.9))
#violin plot of primability across age groups
ggplot(participant_summary, aes(x=group, y=primability_index, fill=group)) +
geom_violin() +
ggtitle("primability x age group") +
labs(y = 'primability_index
(new image level - old image level', x = 'block (first or second half)') +
stat_summary(fun.y=mean, geom="point", shape=23, size=2) +
geom_jitter(shape=16, position=position_jitter(0.2))
#basic scatterplot JITTERED for visualisation
ggplot(participant_summary, aes(x = mean_nback_level, y = primability_index, color = group)) +
ggtitle("mean_nback_level x primability") +
geom_jitter(width = 0.05) +
geom_smooth(method=lm, se = FALSE)
# Other graphs
#scatterplot only block 1
only_1 <- filter(master_summary, block == 1)
ggplot(only_1, aes(x = mean_nback_level, y = primability_index, color = group)) +
ggtitle("mean_nback_level x primability in block 1") +
geom_jitter(width = 0.05) +
geom_smooth(method=lm, se = FALSE)
#scatterplot only block 2
only_2 <- filter(master_summary, block == 2)
ggplot(only_2, aes(x = mean_nback_level, y = primability_index, color = group)) +
ggtitle("mean_nback_level x primability in block 2") +
geom_jitter(width = 0.05) +
geom_smooth(method=lm, se = FALSE)
#bar graph primability index x age (7 8 9)
ggplot(age_means, aes(x=age_group, y=mean_primability, fill = age_group)) +
geom_bar(stat="identity") +
ggtitle("primability x block x age group (7,8,9)") +
scale_fill_manual(values=c("#932422", "#d35450", "#d38381", "#394f68")) +  labs(y = 'primability_index
(new image level - old image level') +
geom_errorbar(aes(ymin= mean_primability - se, ymax= mean_primability + se), width=.2,
position=position_dodge(.9))
#looks at early and late performance on priming test 7 8 9
ggplot(block_age_means, aes(fill=age_group, y=mean_primability, x=as.factor(block))) +
geom_bar(position="dodge", stat="identity") +
scale_fill_manual(values=c("#932422", "#d35450", "#d38381", "#394f68")) +
ggtitle("primability x age group (7,8,9)") +
labs(y = 'primability_index
(new image level - old image level', x = 'block (first or second half)') +
geom_errorbar(aes(ymin= mean_primability - se, ymax= mean_primability + se), width=.2,
position=position_dodge(.9))
#Lantern - skeleton
library(plyr)
library(dplyr)
library(ggplot2)
library(jtools)
#Global drop levels of strings before reading in any data
options(stringsAsFactors = FALSE)
#Reads in data and filters trials we don't want (MIGHT NEED TO CHANGE THIS)
wd <- setwd("~/Desktop/Include Data") #sets WD
nback_files <- list.files(recursive=TRUE, pattern = "*n-back") #Creates list of all nback files
prime_files <- list.files(recursive=TRUE, pattern = "*prime") #Creates list of all prime files
nback_data <-do.call(rbind.fill,lapply(nback_files,read.csv)) # Makes big dataframe of all nback data
prime_data <-do.call(rbind.fill,lapply(prime_files,read.csv)) #Makes big dataframe of all prime data
#filter prime data only by trials that is correct
#Make summary dataframe to be able to run stats on and graph (i.e. each row is a participant with their primability score and age)
# Compare kids + adults primability index (i.e. mean difficulty on new items - mean difficulty on old items)
#do a t.test or use lmer function
#graph this
# Compare kids + adults primability index by splitting the prime test trials into blocks (first half and second half)
# use lmer function
#graph this
View(nback_summary)
#Create list with csv files
file_paths = list.files(path="~/Desktop/Code These", recursive = TRUE, full.names = TRUE)
#Store total number of files
total_paths = length(file_paths)
#Loop over all files
for (f in 1:total_paths){
#Check if prime.csv file
if (grepl("prime.csv", file_paths[f], fixed=TRUE)){
#Import data from csv to dataframe prime_data
prime_data <- read.csv(file=file_paths[f], header=TRUE, sep=",", na.strings = "NA")
#Create new column response_correct
prime_data$response_correct <- 0
#Create new column response_uncertain
prime_data$response_uncertain <- 0
for (i in 1:46){
if (trimws(prime_data[i, "user_response"]) == prime_data[i, "image_name"]){
prime_data[i, "response_correct"] = 1
}
else{
print(prime_data[i, "user_response"], max.levels = 0)
print(prime_data[i, "image_name"], max.levels = 0)
match = readline(prompt="Is this a match? ")
if (match == "y"){
prime_data[i, "response_correct"] = 1
} else if (match == "u"){
prime_data[i, "response_correct"] = 1
prime_data[i, "response_uncertain"] = 1
}
}
setwd(dirname((file_paths[f]))) #sets wd to current participant directory so we overwrite the right csv
write.csv(prime_data, "prime.csv")
}
}
}
#Create list with csv files
file_paths = list.files(path="~/Desktop/Code These", recursive = TRUE, full.names = TRUE)
#Store total number of files
total_paths = length(file_paths)
#Loop over all files
for (f in 1:total_paths){
#Check if prime.csv file
if (grepl("prime.csv", file_paths[f], fixed=TRUE)){
#Import data from csv to dataframe prime_data
prime_data <- read.csv(file=file_paths[f], header=TRUE, sep=",", na.strings = "NA")
#Create new column response_correct
prime_data$response_correct <- 0
#Create new column response_uncertain
prime_data$response_uncertain <- 0
for (i in 1:46){
if (trimws(prime_data[i, "user_response"]) == prime_data[i, "image_name"]){
prime_data[i, "response_correct"] = 1
}
else{
print(prime_data[i, "user_response"], max.levels = 0)
print(prime_data[i, "image_name"], max.levels = 0)
match = readline(prompt="Is this a match? ")
if (match == "y"){
prime_data[i, "response_correct"] = 1
} else if (match == "u"){
prime_data[i, "response_correct"] = 1
prime_data[i, "response_uncertain"] = 1
}
}
setwd(dirname((file_paths[f]))) #sets wd to current participant directory so we overwrite the right csv
write.csv(prime_data, "prime.csv")
}
}
}
